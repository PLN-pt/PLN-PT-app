<p class="light" style="padding: 0px; margin: 0px;">
Em análise léxica, <em>tokenização</em> é o processo de dividir um texto em palavras, frases, símbolos, ou outros elementos com significado, tipicamente chamados de <em>tokens</em>.
</p>
<h5>[% l('requests') %]</h5>
<pre>POST http://api.pln.pt/tokenizer</pre>
<p class="light" style="padding: 0px; margin: 0px;">
Enviar o texto para <em>tokenização</em> no corpo do pedido.
</p>
<h5>[% l('result') %]</h5>
<p class="light" style="padding: 0px; margin: 0px;">
O resultado da operação é uma lista, em formato JSON, em que cada elemento da list é um <em>token</em>.
</p>
<h5>[% l('example') %]</h5>
<p class="light" style="padding: 0px; margin: 0px;">
Por exemplo, dado o seguinte texto:
</p>
<pre class="myc">$ cat input.txt
A Maria tem razão.</pre>
<p class="light" style="padding: 0px; margin: 0px;">
É possível fazer um pedido à API para <em>tokenizar</em> o texto, por exemplo:
</p>
<pre class="myc">$ curl -s -X POST -d @input.txt http://api.pln.pt/tokenizer
["A","Maria","tem","razão","."]</pre>
<h5>[% l('options') %]</h5>
<p class="light" style="padding: 0px; margin: 0px;">
<code>output=json|raw</code><br>
  <code class="opt">json</code> (por omissão) devolve o resultado como um objecto JSON<br>
  <code class="opt">raw</code> devolve o resultado não processado em texto limpo
</p>
<p class="light" style="padding: 0px; margin: 0px;">
<code>sentence=0|1</code><br>
  <code class="opt">1</code> <em>tokenizar</em> por frases<br>
  <code class="opt">0</code> não <em>tokenizar</em> por frases (por omissão)
</p>